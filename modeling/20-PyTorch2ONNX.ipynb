{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.google_utils import *\n",
    "from utils.layers import *\n",
    "from utils.parse_config import *\n",
    "\n",
    "ONNX_EXPORT = False\n",
    "\n",
    "\n",
    "def create_modules(module_defs, img_size, cfg):\n",
    "    # Constructs module list of layer blocks from module configuration in module_defs\n",
    "\n",
    "    img_size = [img_size] * 2 if isinstance(img_size, int) else img_size  # expand if necessary\n",
    "    _ = module_defs.pop(0)  # cfg training hyperparams (unused)\n",
    "    output_filters = [3]  # input channels\n",
    "    module_list = nn.ModuleList()\n",
    "    routs = []  # list of layers which rout to deeper layers\n",
    "    yolo_index = -1\n",
    "\n",
    "    for i, mdef in enumerate(module_defs):\n",
    "        modules = nn.Sequential()\n",
    "\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            bn = mdef['batch_normalize']\n",
    "            filters = mdef['filters']\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride'] if 'stride' in mdef else (mdef['stride_y'], mdef['stride_x'])\n",
    "            if isinstance(k, int):  # single-size conv\n",
    "                modules.add_module('Conv2d', nn.Conv2d(in_channels=output_filters[-1],\n",
    "                                                       out_channels=filters,\n",
    "                                                       kernel_size=k,\n",
    "                                                       stride=stride,\n",
    "                                                       padding=k // 2 if mdef['pad'] else 0,\n",
    "                                                       groups=mdef['groups'] if 'groups' in mdef else 1,\n",
    "                                                       bias=not bn))\n",
    "            else:  # multiple-size conv\n",
    "                modules.add_module('MixConv2d', MixConv2d(in_ch=output_filters[-1],\n",
    "                                                          out_ch=filters,\n",
    "                                                          k=k,\n",
    "                                                          stride=stride,\n",
    "                                                          bias=not bn))\n",
    "\n",
    "            if bn:\n",
    "                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4))\n",
    "            else:\n",
    "                routs.append(i)  # detection output (goes into yolo layer)\n",
    "\n",
    "            if mdef['activation'] == 'leaky':  # activation study https://github.com/ultralytics/yolov3/issues/441\n",
    "                modules.add_module('activation', nn.LeakyReLU(0.1, inplace=True))\n",
    "            elif mdef['activation'] == 'swish':\n",
    "                modules.add_module('activation', Swish())\n",
    "            elif mdef['activation'] == 'mish':\n",
    "                modules.add_module('activation', Mish())\n",
    "            elif mdef['activation'] == 'relu':\n",
    "                modules.add_module('activation', nn.ReLU())\n",
    "\n",
    "        elif mdef['type'] == 'BatchNorm2d':\n",
    "            filters = output_filters[-1]\n",
    "            modules = nn.BatchNorm2d(filters, momentum=0.03, eps=1E-4)\n",
    "            if i == 0 and filters == 3:  # normalize RGB image\n",
    "                # imagenet mean and var https://pytorch.org/docs/stable/torchvision/models.html#classification\n",
    "                modules.running_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "                modules.running_var = torch.tensor([0.0524, 0.0502, 0.0506])\n",
    "\n",
    "        elif mdef['type'] == 'maxpool':\n",
    "            k = mdef['size']  # kernel size\n",
    "            stride = mdef['stride']\n",
    "            maxpool = nn.MaxPool2d(kernel_size=k, stride=stride, padding=(k - 1) // 2)\n",
    "            if k == 2 and stride == 1:  # yolov3-tiny\n",
    "                modules.add_module('ZeroPad2d', nn.ZeroPad2d((0, 1, 0, 1)))\n",
    "                modules.add_module('MaxPool2d', maxpool)\n",
    "            else:\n",
    "                modules = maxpool\n",
    "\n",
    "        elif mdef['type'] == 'upsample':\n",
    "            if ONNX_EXPORT:  # explicitly state size, avoid scale_factor\n",
    "                g = (yolo_index + 1) * 2 / 32  # gain\n",
    "                modules = nn.Upsample(size=tuple(int(x * g) for x in img_size))  # img_size = (320, 192)\n",
    "            else:\n",
    "                modules = nn.Upsample(scale_factor=mdef['stride'])\n",
    "\n",
    "        elif mdef['type'] == 'route':  # nn.Sequential() placeholder for 'route' layer\n",
    "            layers = mdef['layers']\n",
    "            filters = sum([output_filters[l + 1 if l > 0 else l] for l in layers])\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = FeatureConcat(layers=layers)\n",
    "\n",
    "        elif mdef['type'] == 'shortcut':  # nn.Sequential() placeholder for 'shortcut' layer\n",
    "            layers = mdef['from']\n",
    "            filters = output_filters[-1]\n",
    "            routs.extend([i + l if l < 0 else l for l in layers])\n",
    "            modules = WeightedFeatureFusion(layers=layers, weight='weights_type' in mdef)\n",
    "\n",
    "        elif mdef['type'] == 'reorg3d':  # yolov3-spp-pan-scale\n",
    "            pass\n",
    "\n",
    "        elif mdef['type'] == 'yolo':\n",
    "            yolo_index += 1\n",
    "            stride = [32, 16, 8]  # P5, P4, P3 strides\n",
    "            if any(x in cfg for x in ['panet', 'yolov4', 'cd53']):  # stride order reversed\n",
    "                stride = list(reversed(stride))\n",
    "            layers = mdef['from'] if 'from' in mdef else []\n",
    "            modules = YOLOLayer(anchors=mdef['anchors'][mdef['mask']],  # anchor list\n",
    "                                nc=mdef['classes'],  # number of classes\n",
    "                                img_size=img_size,  # (416, 416)\n",
    "                                yolo_index=yolo_index,  # 0, 1, 2...\n",
    "                                layers=layers,  # output layers\n",
    "                                stride=stride[yolo_index])\n",
    "\n",
    "            # Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)\n",
    "            try:\n",
    "                j = layers[yolo_index] if 'from' in mdef else -1\n",
    "                # If previous layer is a dropout layer, get the one before\n",
    "                if module_list[j].__class__.__name__ == 'Dropout':\n",
    "                    j -= 1\n",
    "                bias_ = module_list[j][0].bias  # shape(255,)\n",
    "                bias = bias_[:modules.no * modules.na].view(modules.na, -1)  # shape(3,85)\n",
    "                bias[:, 4] += -4.5  # obj\n",
    "                bias[:, 5:] += math.log(0.6 / (modules.nc - 0.99))  # cls (sigmoid(p) = 1/nc)\n",
    "                module_list[j][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)\n",
    "            except:\n",
    "                print('WARNING: smart bias initialization failure.')\n",
    "\n",
    "        elif mdef['type'] == 'dropout':\n",
    "            perc = float(mdef['probability'])\n",
    "            modules = nn.Dropout(p=perc)\n",
    "        else:\n",
    "            print('Warning: Unrecognized Layer Type: ' + mdef['type'])\n",
    "\n",
    "        # Register module list and number of output filters\n",
    "        module_list.append(modules)\n",
    "        output_filters.append(filters)\n",
    "\n",
    "    routs_binary = [False] * (i + 1)\n",
    "    for i in routs:\n",
    "        routs_binary[i] = True\n",
    "    return module_list, routs_binary\n",
    "\n",
    "\n",
    "class YOLOLayer(nn.Module):\n",
    "    def __init__(self, anchors, nc, img_size, yolo_index, layers, stride):\n",
    "        super(YOLOLayer, self).__init__()\n",
    "        self.anchors = torch.Tensor(anchors)\n",
    "        self.index = yolo_index  # index of this layer in layers\n",
    "        self.layers = layers  # model output layer indices\n",
    "        self.stride = stride  # layer stride\n",
    "        self.nl = len(layers)  # number of output layers (3)\n",
    "        self.na = len(anchors)  # number of anchors (3)\n",
    "        self.nc = nc  # number of classes (80)\n",
    "        self.no = nc + 5  # number of outputs (85)\n",
    "        self.nx, self.ny, self.ng = 0, 0, 0  # initialize number of x, y gridpoints\n",
    "        self.anchor_vec = self.anchors / self.stride\n",
    "        self.anchor_wh = self.anchor_vec.view(1, self.na, 1, 1, 2)\n",
    "\n",
    "        if ONNX_EXPORT:\n",
    "            self.training = False\n",
    "            self.create_grids((img_size[1] // stride, img_size[0] // stride))  # number x, y grid points\n",
    "\n",
    "    def create_grids(self, ng=(13, 13), device='cpu'):\n",
    "        self.nx, self.ny = ng  # x and y grid size\n",
    "        self.ng = torch.tensor(ng, dtype=torch.float)\n",
    "\n",
    "        # build xy offsets\n",
    "        if not self.training:\n",
    "            yv, xv = torch.meshgrid([torch.arange(self.ny, device=device), torch.arange(self.nx, device=device)])\n",
    "            self.grid = torch.stack((xv, yv), 2).view((1, 1, self.ny, self.nx, 2)).float()\n",
    "\n",
    "        if self.anchor_vec.device != device:\n",
    "            self.anchor_vec = self.anchor_vec.to(device)\n",
    "            self.anchor_wh = self.anchor_wh.to(device)\n",
    "\n",
    "    def forward(self, p, out):\n",
    "        ASFF = False  # https://arxiv.org/abs/1911.09516\n",
    "        if ASFF:\n",
    "            i, n = self.index, self.nl  # index in layers, number of layers\n",
    "            p = out[self.layers[i]]\n",
    "            bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "            if (self.nx, self.ny) != (nx, ny):\n",
    "                self.create_grids((nx, ny), p.device)\n",
    "\n",
    "            # outputs and weights\n",
    "            # w = F.softmax(p[:, -n:], 1)  # normalized weights\n",
    "            w = torch.sigmoid(p[:, -n:]) * (2 / n)  # sigmoid weights (faster)\n",
    "            # w = w / w.sum(1).unsqueeze(1)  # normalize across layer dimension\n",
    "\n",
    "            # weighted ASFF sum\n",
    "            p = out[self.layers[i]][:, :-n] * w[:, i:i + 1]\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    p += w[:, j:j + 1] * \\\n",
    "                         F.interpolate(out[self.layers[j]][:, :-n], size=[ny, nx], mode='bilinear', align_corners=False)\n",
    "\n",
    "        elif ONNX_EXPORT:\n",
    "            bs = 1  # batch size\n",
    "        else:\n",
    "            bs, _, ny, nx = p.shape  # bs, 255, 13, 13\n",
    "            if (self.nx, self.ny) != (nx, ny):\n",
    "                self.create_grids((nx, ny), p.device)\n",
    "\n",
    "        # p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)\n",
    "        p = p.view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n",
    "\n",
    "        if self.training:\n",
    "            return p\n",
    "\n",
    "        elif ONNX_EXPORT:\n",
    "            # Avoid broadcasting for ANE operations\n",
    "            m = self.na * self.nx * self.ny\n",
    "            ng = 1. / self.ng.repeat(m, 1)\n",
    "            grid = self.grid.repeat(1, self.na, 1, 1, 1).view(m, 2)\n",
    "            anchor_wh = self.anchor_wh.repeat(1, 1, self.nx, self.ny, 1).view(m, 2) * ng\n",
    "\n",
    "            p = p.view(m, self.no)\n",
    "            xy = torch.sigmoid(p[:, 0:2]) + grid  # x, y\n",
    "            wh = torch.exp(p[:, 2:4]) * anchor_wh  # width, height\n",
    "            p_cls = torch.sigmoid(p[:, 4:5]) if self.nc == 1 else \\\n",
    "                torch.sigmoid(p[:, 5:self.no]) * torch.sigmoid(p[:, 4:5])  # conf\n",
    "            return p_cls, xy * ng, wh\n",
    "\n",
    "        else:  # inference\n",
    "            io = p.clone()  # inference output\n",
    "            io[..., :2] = torch.sigmoid(io[..., :2]) + self.grid  # xy\n",
    "            io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method\n",
    "            io[..., :4] *= self.stride\n",
    "            torch.sigmoid_(io[..., 4:])\n",
    "            return io.view(bs, -1, self.no), p  # view [1, 3, 13, 13, 85] as [1, 507, 85]\n",
    "\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    # YOLOv3 object detection model\n",
    "\n",
    "    def __init__(self, cfg, img_size=(416, 416), verbose=False):\n",
    "        super(Darknet, self).__init__()\n",
    "\n",
    "        self.module_defs = parse_model_cfg(cfg)\n",
    "        self.module_list, self.routs = create_modules(self.module_defs, img_size, cfg)\n",
    "        self.yolo_layers = get_yolo_layers(self)\n",
    "        # torch_utils.initialize_weights(self)\n",
    "\n",
    "        # Darknet Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.array([0, 2, 5], dtype=np.int32)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.array([0], dtype=np.int64)  # (int64) number of images seen during training\n",
    "        self.info(verbose) if not ONNX_EXPORT else None  # print model description\n",
    "\n",
    "    def forward(self, x, augment=False, verbose=False):\n",
    "\n",
    "        if not augment:\n",
    "            return self.forward_once(x)\n",
    "        else:  # Augment images (inference and test only) https://github.com/ultralytics/yolov3/issues/931\n",
    "            img_size = x.shape[-2:]  # height, width\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            y = []\n",
    "            for i, xi in enumerate((x,\n",
    "                                    torch_utils.scale_img(x.flip(3), s[0], same_shape=False),  # flip-lr and scale\n",
    "                                    torch_utils.scale_img(x, s[1], same_shape=False),  # scale\n",
    "                                    )):\n",
    "                # cv2.imwrite('img%g.jpg' % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])\n",
    "                y.append(self.forward_once(xi)[0])\n",
    "\n",
    "            y[1][..., :4] /= s[0]  # scale\n",
    "            y[1][..., 0] = img_size[1] - y[1][..., 0]  # flip lr\n",
    "            y[2][..., :4] /= s[1]  # scale\n",
    "\n",
    "            # for i, yi in enumerate(y):  # coco small, medium, large = < 32**2 < 96**2 <\n",
    "            #     area = yi[..., 2:4].prod(2)[:, :, None]\n",
    "            #     if i == 1:\n",
    "            #         yi *= (area < 96. ** 2).float()\n",
    "            #     elif i == 2:\n",
    "            #         yi *= (area > 32. ** 2).float()\n",
    "            #     y[i] = yi\n",
    "\n",
    "            y = torch.cat(y, 1)\n",
    "            return y, None\n",
    "\n",
    "    def forward_once(self, x, augment=False, verbose=False):\n",
    "        img_size = x.shape[-2:]  # height, width\n",
    "        yolo_out, out = [], []\n",
    "        if verbose:\n",
    "            print('0', x.shape)\n",
    "            str = ''\n",
    "\n",
    "        # Augment images (inference and test only)\n",
    "        if augment:  # https://github.com/ultralytics/yolov3/issues/931\n",
    "            nb = x.shape[0]  # batch size\n",
    "            s = [0.83, 0.67]  # scales\n",
    "            x = torch.cat((x,\n",
    "                           torch_utils.scale_img(x.flip(3), s[0]),  # flip-lr and scale\n",
    "                           torch_utils.scale_img(x, s[1]),  # scale\n",
    "                           ), 0)\n",
    "\n",
    "        for i, module in enumerate(self.module_list):\n",
    "            name = module.__class__.__name__\n",
    "            if name in ['WeightedFeatureFusion', 'FeatureConcat']:  # sum, concat\n",
    "                if verbose:\n",
    "                    l = [i - 1] + module.layers  # layers\n",
    "                    sh = [list(x.shape)] + [list(out[i].shape) for i in module.layers]  # shapes\n",
    "                    str = ' >> ' + ' + '.join(['layer %g %s' % x for x in zip(l, sh)])\n",
    "                x = module(x, out)  # WeightedFeatureFusion(), FeatureConcat()\n",
    "            elif name == 'YOLOLayer':\n",
    "                yolo_out.append(module(x, out))\n",
    "            else:  # run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.\n",
    "                x = module(x)\n",
    "\n",
    "            out.append(x if self.routs[i] else [])\n",
    "            if verbose:\n",
    "                print('%g/%g %s -' % (i, len(self.module_list), name), list(x.shape), str)\n",
    "                str = ''\n",
    "\n",
    "        if self.training:  # train\n",
    "            return yolo_out\n",
    "        elif ONNX_EXPORT:  # export\n",
    "            x = [torch.cat(x, 0) for x in zip(*yolo_out)]\n",
    "            return x[0], torch.cat(x[1:3], 1)  # scores, boxes: 3780x80, 3780x4\n",
    "        else:  # inference or test\n",
    "            x, p = zip(*yolo_out)  # inference output, training output\n",
    "            x = torch.cat(x, 1)  # cat yolo outputs\n",
    "            if augment:  # de-augment results\n",
    "                x = torch.split(x, nb, dim=0)\n",
    "                x[1][..., :4] /= s[0]  # scale\n",
    "                x[1][..., 0] = img_size[1] - x[1][..., 0]  # flip lr\n",
    "                x[2][..., :4] /= s[1]  # scale\n",
    "                x = torch.cat(x, 1)\n",
    "            return x, p\n",
    "\n",
    "    def fuse(self):\n",
    "        # Fuse Conv2d + BatchNorm2d layers throughout model\n",
    "        print('Fusing layers...')\n",
    "        fused_list = nn.ModuleList()\n",
    "        for a in list(self.children())[0]:\n",
    "            if isinstance(a, nn.Sequential):\n",
    "                for i, b in enumerate(a):\n",
    "                    if isinstance(b, nn.modules.batchnorm.BatchNorm2d):\n",
    "                        # fuse this bn layer with the previous conv2d layer\n",
    "                        conv = a[i - 1]\n",
    "                        fused = torch_utils.fuse_conv_and_bn(conv, b)\n",
    "                        a = nn.Sequential(fused, *list(a.children())[i + 1:])\n",
    "                        break\n",
    "            fused_list.append(a)\n",
    "        self.module_list = fused_list\n",
    "        self.info() if not ONNX_EXPORT else None  # yolov3-spp reduced from 225 to 152 layers\n",
    "\n",
    "    def info(self, verbose=False):\n",
    "        torch_utils.model_info(self, verbose)\n",
    "\n",
    "\n",
    "def get_yolo_layers(model):\n",
    "    return [i for i, m in enumerate(model.module_list) if m.__class__.__name__ == 'YOLOLayer']  # [89, 101, 113]\n",
    "\n",
    "\n",
    "def load_darknet_weights(self, weights, cutoff=-1):\n",
    "    # Parses and loads the weights stored in 'weights'\n",
    "\n",
    "    # Establish cutoffs (load layers between 0 and cutoff. if cutoff = -1 all are loaded)\n",
    "    file = Path(weights).name\n",
    "    if file == 'darknet53.conv.74':\n",
    "        cutoff = 75\n",
    "    elif file == 'yolov3-tiny.conv.15':\n",
    "        cutoff = 15\n",
    "\n",
    "    # Read weights file\n",
    "    with open(weights, 'rb') as f:\n",
    "        # Read Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346\n",
    "        self.version = np.fromfile(f, dtype=np.int32, count=3)  # (int32) version info: major, minor, revision\n",
    "        self.seen = np.fromfile(f, dtype=np.int64, count=1)  # (int64) number of images seen during training\n",
    "\n",
    "        weights = np.fromfile(f, dtype=np.float32)  # the rest are weights\n",
    "\n",
    "    ptr = 0\n",
    "    for i, (mdef, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n",
    "        if mdef['type'] == 'convolutional':\n",
    "            conv = module[0]\n",
    "            if mdef['batch_normalize']:\n",
    "                # Load BN bias, weights, running mean and running variance\n",
    "                bn = module[1]\n",
    "                nb = bn.bias.numel()  # number of biases\n",
    "                # Bias\n",
    "                bn.bias.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.bias))\n",
    "                ptr += nb\n",
    "                # Weight\n",
    "                bn.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.weight))\n",
    "                ptr += nb\n",
    "                # Running Mean\n",
    "                bn.running_mean.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_mean))\n",
    "                ptr += nb\n",
    "                # Running Var\n",
    "                bn.running_var.data.copy_(torch.from_numpy(weights[ptr:ptr + nb]).view_as(bn.running_var))\n",
    "                ptr += nb\n",
    "            else:\n",
    "                # Load conv. bias\n",
    "                nb = conv.bias.numel()\n",
    "                conv_b = torch.from_numpy(weights[ptr:ptr + nb]).view_as(conv.bias)\n",
    "                conv.bias.data.copy_(conv_b)\n",
    "                ptr += nb\n",
    "            # Load conv. weights\n",
    "            nw = conv.weight.numel()  # number of weights\n",
    "            conv.weight.data.copy_(torch.from_numpy(weights[ptr:ptr + nw]).view_as(conv.weight))\n",
    "            ptr += nw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsz = (320, 512)\n",
    "imgsz = 320\n",
    "\n",
    "cfg = 'cfg/yolo-fastest.cfg'\n",
    "weights = 'weights/best.weights'\n",
    "device = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Summary: 253 layers, 290066 parameters, 290066 gradients\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = Darknet(cfg, imgsz)\n",
    "\n",
    "# Load weights\n",
    "if weights.endswith('.pt'):  # pytorch format\n",
    "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "else:  # darknet format\n",
    "    load_darknet_weights(model, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): Dropout(p=0.15, inplace=False)\n",
       "    (16): WeightedFeatureFusion()\n",
       "    (17): Sequential(\n",
       "      (Conv2d): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Sequential(\n",
       "      (Conv2d): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(8, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): Dropout(p=0.15, inplace=False)\n",
       "    (21): WeightedFeatureFusion()\n",
       "    (22): Sequential(\n",
       "      (Conv2d): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (Conv2d): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (24): Sequential(\n",
       "      (Conv2d): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(8, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): Sequential(\n",
       "      (Conv2d): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (Conv2d): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): Sequential(\n",
       "      (Conv2d): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(8, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (28): Dropout(p=0.15, inplace=False)\n",
       "    (29): WeightedFeatureFusion()\n",
       "    (30): Sequential(\n",
       "      (Conv2d): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (31): Sequential(\n",
       "      (Conv2d): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (Conv2d): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(8, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (33): Dropout(p=0.15, inplace=False)\n",
       "    (34): WeightedFeatureFusion()\n",
       "    (35): Sequential(\n",
       "      (Conv2d): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): Sequential(\n",
       "      (Conv2d): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (37): Sequential(\n",
       "      (Conv2d): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (Conv2d): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (40): Sequential(\n",
       "      (Conv2d): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (41): Dropout(p=0.15, inplace=False)\n",
       "    (42): WeightedFeatureFusion()\n",
       "    (43): Sequential(\n",
       "      (Conv2d): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): Sequential(\n",
       "      (Conv2d): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (46): Dropout(p=0.15, inplace=False)\n",
       "    (47): WeightedFeatureFusion()\n",
       "    (48): Sequential(\n",
       "      (Conv2d): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (49): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (Conv2d): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (51): Dropout(p=0.15, inplace=False)\n",
       "    (52): WeightedFeatureFusion()\n",
       "    (53): Sequential(\n",
       "      (Conv2d): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (55): Sequential(\n",
       "      (Conv2d): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (56): Dropout(p=0.15, inplace=False)\n",
       "    (57): WeightedFeatureFusion()\n",
       "    (58): Sequential(\n",
       "      (Conv2d): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (59): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (60): Sequential(\n",
       "      (Conv2d): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(24, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (61): Sequential(\n",
       "      (Conv2d): Conv2d(24, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (62): Sequential(\n",
       "      (Conv2d): Conv2d(136, 136, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=136, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (Conv2d): Conv2d(136, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(24, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (64): Dropout(p=0.15, inplace=False)\n",
       "    (65): WeightedFeatureFusion()\n",
       "    (66): Sequential(\n",
       "      (Conv2d): Conv2d(24, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): Sequential(\n",
       "      (Conv2d): Conv2d(136, 136, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=136, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (68): Sequential(\n",
       "      (Conv2d): Conv2d(136, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(24, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (69): Dropout(p=0.15, inplace=False)\n",
       "    (70): WeightedFeatureFusion()\n",
       "    (71): Sequential(\n",
       "      (Conv2d): Conv2d(24, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (Conv2d): Conv2d(136, 136, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=136, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (73): Sequential(\n",
       "      (Conv2d): Conv2d(136, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(24, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (74): Dropout(p=0.15, inplace=False)\n",
       "    (75): WeightedFeatureFusion()\n",
       "    (76): Sequential(\n",
       "      (Conv2d): Conv2d(24, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (77): Sequential(\n",
       "      (Conv2d): Conv2d(136, 136, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=136, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (78): Sequential(\n",
       "      (Conv2d): Conv2d(136, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(24, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (79): Dropout(p=0.15, inplace=False)\n",
       "    (80): WeightedFeatureFusion()\n",
       "    (81): Sequential(\n",
       "      (Conv2d): Conv2d(24, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (82): Sequential(\n",
       "      (Conv2d): Conv2d(136, 136, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=136, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(136, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (83): Sequential(\n",
       "      (Conv2d): Conv2d(136, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (Conv2d): Conv2d(48, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (85): Sequential(\n",
       "      (Conv2d): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (86): Sequential(\n",
       "      (Conv2d): Conv2d(224, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (87): Dropout(p=0.15, inplace=False)\n",
       "    (88): WeightedFeatureFusion()\n",
       "    (89): Sequential(\n",
       "      (Conv2d): Conv2d(48, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (90): Sequential(\n",
       "      (Conv2d): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (91): Sequential(\n",
       "      (Conv2d): Conv2d(224, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (92): Dropout(p=0.15, inplace=False)\n",
       "    (93): WeightedFeatureFusion()\n",
       "    (94): Sequential(\n",
       "      (Conv2d): Conv2d(48, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (95): Sequential(\n",
       "      (Conv2d): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (96): Sequential(\n",
       "      (Conv2d): Conv2d(224, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (97): Dropout(p=0.15, inplace=False)\n",
       "    (98): WeightedFeatureFusion()\n",
       "    (99): Sequential(\n",
       "      (Conv2d): Conv2d(48, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (100): Sequential(\n",
       "      (Conv2d): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (101): Sequential(\n",
       "      (Conv2d): Conv2d(224, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (102): Dropout(p=0.15, inplace=False)\n",
       "    (103): WeightedFeatureFusion()\n",
       "    (104): Sequential(\n",
       "      (Conv2d): Conv2d(48, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (105): Sequential(\n",
       "      (Conv2d): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=224, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(224, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (106): Sequential(\n",
       "      (Conv2d): Conv2d(224, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(48, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (107): Dropout(p=0.15, inplace=False)\n",
       "    (108): WeightedFeatureFusion()\n",
       "    (109): Sequential(\n",
       "      (Conv2d): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (110): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (111): Sequential(\n",
       "      (Conv2d): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (112): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (113): Sequential(\n",
       "      (Conv2d): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (114): Sequential(\n",
       "      (Conv2d): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (115): YOLOLayer()\n",
       "    (116): FeatureConcat()\n",
       "    (117): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (118): FeatureConcat()\n",
       "    (119): Sequential(\n",
       "      (Conv2d): Conv2d(232, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (120): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (121): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (122): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (123): Sequential(\n",
       "      (Conv2d): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(96, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (124): Sequential(\n",
       "      (Conv2d): Conv2d(96, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (125): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# Input to the model\n",
    "x = torch.randn(batch_size, 3, 320, 512, requires_grad=True)\n",
    "torch_out = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"cfg/yolo-fastest.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['images'],   # the model's input names\n",
    "                  output_names = ['classes','boxes'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                'output' : {0 : 'batch_size'}}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"yolo-fastest.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ant[value = <Scalar Tensor []>]()\n  %1029 = Range(%1027, %1026, %1028)\n  %1030 = Shape(%990)\n  %1031 = Constant[value = <Scalar Tensor []>]()\n  %1032 = Gather[axis = 0](%1030, %1031)\n  %1033 = Cast[to = 7](%1032)\n  %1034 = Constant[value = <Scalar Tensor []>]()\n  %1035 = Constant[value = <Scalar Tensor []>]()\n  %1036 = Range(%1034, %1033, %1035)\n  %1037 = Shape(%990)\n  %1038 = Constant[value = <Scalar Tensor []>]()\n  %1039 = Gather[axis = 0](%1037, %1038)\n  %1040 = Cast[to = 7](%1039)\n  %1041 = Constant[value = <Scalar Tensor []>]()\n  %1042 = Constant[value = <Scalar Tensor []>]()\n  %1043 = Range(%1041, %1040, %1042)\n  %1044 = Constant[value = <Tensor>]()\n  %1045 = Constant[value = <Tensor>]()\n  %1046 = Constant[value = <Tensor>]()\n  %1047 = Constant[value = <Tensor>]()\n  %1048 = Slice(%1043, %1045, %1046, %1044, %1047)\n  %1049 = Constant[value = <Tensor>]()\n  %1050 = Reshape(%1015, %1049)\n  %1051 = Constant[value = <Tensor>]()\n  %1052 = Reshape(%1022, %1051)\n  %1053 = Constant[value = <Tensor>]()\n  %1054 = Reshape(%1029, %1053)\n  %1055 = Constant[value = <Tensor>]()\n  %1056 = Reshape(%1036, %1055)\n  %1057 = Constant[value = <Tensor>]()\n  %1058 = Reshape(%1048, %1057)\n  %1059 = Add(%1050, %1052)\n  %1060 = Add(%1059, %1054)\n  %1061 = Add(%1060, %1056)\n  %1062 = Add(%1061, %1058)\n  %1063 = Shape(%1062)\n  %1064 = Shape(%1063)\n  %1065 = ConstantOfShape[value = <Tensor>](%1064)\n  %1066 = Constant[value = <Scalar Tensor []>]()\n  %1067 = Mul(%1065, %1066)\n  %1068 = Equal(%1063, %1067)\n  %1069 = Where(%1068, %1065, %1063)\n  %1070 = Expand(%1050, %1069)\n  %1071 = Unsqueeze[axes = [-1]](%1070)\n  %1072 = Shape(%1063)\n  %1073 = ConstantOfShape[value = <Tensor>](%1072)\n  %1074 = Constant[value = <Scalar Tensor []>]()\n  %1075 = Mul(%1073, %1074)\n  %1076 = Equal(%1063, %1075)\n  %1077 = Where(%1076, %1073, %1063)\n  %1078 = Expand(%1052, %1077)\n  %1079 = Unsqueeze[axes = [-1]](%1078)\n  %1080 = Shape(%1063)\n  %1081 = ConstantOfShape[value = <Tensor>](%1080)\n  %1082 = Constant[value = <Scalar Tensor []>]()\n  %1083 = Mul(%1081, %1082)\n  %1084 = Equal(%1063, %1083)\n  %1085 = Where(%1084, %1081, %1063)\n  %1086 = Expand(%1054, %1085)\n  %1087 = Unsqueeze[axes = [-1]](%1086)\n  %1088 = Shape(%1063)\n  %1089 = ConstantOfShape[value = <Tensor>](%1088)\n  %1090 = Constant[value = <Scalar Tensor []>]()\n  %1091 = Mul(%1089, %1090)\n  %1092 = Equal(%1063, %1091)\n  %1093 = Where(%1092, %1089, %1063)\n  %1094 = Expand(%1056, %1093)\n  %1095 = Unsqueeze[axes = [-1]](%1094)\n  %1096 = Shape(%1063)\n  %1097 = ConstantOfShape[value = <Tensor>](%1096)\n  %1098 = Constant[value = <Scalar Tensor []>]()\n  %1099 = Mul(%1097, %1098)\n  %1100 = Equal(%1063, %1099)\n  %1101 = Where(%1100, %1097, %1063)\n  %1102 = Expand(%1058, %1101)\n  %1103 = Unsqueeze[axes = [-1]](%1102)\n  %1104 = Concat[axis = -1](%1071, %1079, %1087, %1095, %1103)\n  %1105 = Shape(%990)\n  %1106 = Constant[value = <Tensor>]()\n  %1107 = Constant[value = <Tensor>]()\n  %1108 = Constant[value = <Tensor>]()\n  %1109 = Slice(%1105, %1107, %1108, %1106)\n  %1110 = Concat[axis = 0](%1063, %1109)\n  %1111 = Reshape(%1008, %1110)\n  %1112 = ScatterND(%990, %1104, %1111)\n  %1115 = Unsqueeze[axes = [0]](%732)\n  %1118 = Concat[axis = 0](%1115, %1543, %1544)\n  %1119 = Reshape(%1112, %1118)\n  %1128 = Constant[value = <Tensor>]()\n  %1129 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%718, %1128, %1549)\n  %1130 = Concat[axis = 1](%1129, %665)\n  %1131 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1130, %module_list.119.Conv2d.weight)\n  %1132 = BatchNormalization[epsilon = 9.99999974737875e-05, momentum = 0.970000028610229](%1131, %module_list.119.BatchNorm2d.weight, %module_list.119.BatchNorm2d.bias, %module_list.119.BatchNorm2d.running_mean, %module_list.119.BatchNorm2d.running_var)\n  %1133 = LeakyRelu[alpha = 0.100000001490116](%1132)\n  %1134 = Conv[dilations = [1, 1], group = 96, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%1133, %module_list.120.Conv2d.weight)\n  %1135 = BatchNormalization[epsilon = 9.99999974737875e-05, momentum = 0.970000028610229](%1134, %module_list.120.BatchNorm2d.weight, %module_list.120.BatchNorm2d.bias, %module_list.120.BatchNorm2d.running_mean, %module_list.120.BatchNorm2d.running_var)\n  %1136 = LeakyRelu[alpha = 0.100000001490116](%1135)\n  %1137 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1136, %module_list.121.Conv2d.weight)\n  %1138 = BatchNormalization[epsilon = 9.99999974737875e-05, momentum = 0.970000028610229](%1137, %module_list.121.BatchNorm2d.weight, %module_list.121.BatchNorm2d.bias, %module_list.121.BatchNorm2d.running_mean, %module_list.121.BatchNorm2d.running_var)\n  %1139 = Conv[dilations = [1, 1], group = 96, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%1138, %module_list.122.Conv2d.weight)\n  %1140 = BatchNormalization[epsilon = 9.99999974737875e-05, momentum = 0.970000028610229](%1139, %module_list.122.BatchNorm2d.weight, %module_list.122.BatchNorm2d.bias, %module_list.122.BatchNorm2d.running_mean, %module_list.122.BatchNorm2d.running_var)\n  %1141 = LeakyRelu[alpha = 0.100000001490116](%1140)\n  %1142 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1141, %module_list.123.Conv2d.weight)\n  %1143 = BatchNormalization[epsilon = 9.99999974737875e-05, momentum = 0.970000028610229](%1142, %module_list.123.BatchNorm2d.weight, %module_list.123.BatchNorm2d.bias, %module_list.123.BatchNorm2d.running_mean, %module_list.123.BatchNorm2d.running_var)\n  %1144 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%1143, %module_list.124.Conv2d.weight, %module_list.124.Conv2d.bias)\n  %1145 = Shape(%1144)\n  %1146 = Constant[value = <Scalar Tensor []>]()\n  %1147 = Gather[axis = 0](%1145, %1146)\n  %1152 = Unsqueeze[axes = [0]](%1147)\n  %1157 = Concat[axis = 0](%1152, %1550, %1551, %1552, %1553)\n  %1158 = Reshape(%1144, %1157)\n  %1159 = Transpose[perm = [0, 1, 3, 4, 2]](%1158)\n  %1160 = Constant[value = <Tensor>]()\n  %1161 = Constant[value = <Tensor>]()\n  %1162 = Constant[value = <Tensor>]()\n  %1163 = Constant[value = <Tensor>]()\n  %1164 = Slice(%1159, %1161, %1162, %1160, %1163)\n  %1165 = Sigmoid(%1164)\n  %1166 = Constant[value = <Tensor>]()\n  %1167 = Add(%1165, %1166)\n  %1168 = Constant[value = <Tensor>]()\n  %1169 = Reshape(%1167, %1168)\n  %1170 = Constant[value = <Tensor>]()\n  %1172 = ConstantOfShape[value = <Tensor>](%1554)\n  %1173 = Constant[value = <Scalar Tensor []>]()\n  %1174 = Mul(%1172, %1173)\n  %1175 = Constant[value = <Tensor>]()\n  %1176 = Equal(%1175, %1174)\n  %1177 = Where(%1176, %1172, %1170)\n  %1178 = Expand(%1169, %1177)\n  %1179 = Shape(%1159)\n  %1180 = Constant[value = <Scalar Tensor []>]()\n  %1181 = Gather[axis = 0](%1179, %1180)\n  %1182 = Cast[to = 7](%1181)\n  %1183 = Constant[value = <Scalar Tensor []>]()\n  %1184 = Constant[value = <Scalar Tensor []>]()\n  %1185 = Range(%1183, %1182, %1184)\n  %1186 = Shape(%1159)\n  %1187 = Constant[value = <Scalar Tensor []>]()\n  %1188 = Gather[axis = 0](%1186, %1187)\n  %1189 = Cast[to = 7](%1188)\n  %1190 = Constant[value = <Scalar Tensor []>]()\n  %1191 = Constant[value = <Scalar Tensor []>]()\n  %1192 = Range(%1190, %1189, %1191)\n  %1193 = Shape(%1159)\n  %1194 = Constant[value = <Scalar Tensor []>]()\n  %1195 = Gather[axis = 0](%1193, %1194)\n  %1196 = Cast[to = 7](%1195)\n  %1197 = Constant[value = <Scalar Tensor []>]()\n  %1198 = Constant[value = <Scalar Tensor []>]()\n  %1199 = Range(%1197, %1196, %1198)\n  %1200 = Shape(%1159)\n  %1201 = Constant[value = <Scalar Tensor []>]()\n  %1202 = Gather[axis = 0](%1200, %1201)\n  %1203 = Cast[to = 7](%1202)\n  %1204 = Constant[value = <Scalar Tensor []>]()\n  %1205 = Constant[value = <Scalar Tensor []>]()\n  %1206 = Range(%1204, %1203, %1205)\n  %1207 = Shape(%1159)\n  %1208 = Constant[value = <Scalar Tensor []>]()\n  %1209 = Gather[axis = 0](%1207, %1208)\n  %1210 = Cast[to = 7](%1209)\n  %1211 = Constant[value = <Scalar Tensor []>]()\n  %1212 = Constant[value = <Scalar Tensor []>]()\n  %1213 = Range(%1211, %1210, %1212)\n  %1214 = Constant[value = <Tensor>]()\n  %1215 = Constant[value = <Tensor>]()\n  %1216 = Constant[value = <Tensor>]()\n  %1217 = Constant[value = <Tensor>]()\n  %1218 = Slice(%1213, %1215, %1216, %1214, %1217)\n  %1219 = Constant[value = <Tensor>]()\n  %1220 = Reshape(%1185, %1219)\n  %1221 = Constant[value = <Tensor>]()\n  %1222 = Reshape(%1192, %1221)\n  %1223 = Constant[value = <Tensor>]()\n  %1224 = Reshape(%1199, %1223)\n  %1225 = Constant[value = <Tensor>]()\n  %1226 = Reshape(%1206, %1225)\n  %1227 = Constant[value = <Tensor>]()\n  %1228 = Reshape(%1218, %1227)\n  %1229 = Add(%1220, %1222)\n  %1230 = Add(%1229, %1224)\n  %1231 = Add(%1230, %1226)\n  %1232 = Add(%1231, %1228)\n  %1233 = Shape(%1232)\n  %1234 = Shape(%1233)\n  %1235 = ConstantOfShape[value = <Tensor>](%1234)\n  %1236 = Constant[value = <Scalar Tensor []>]()\n  %1237 = Mul(%1235, %1236)\n  %1238 = Equal(%1233, %1237)\n  %1239 = Where(%1238, %1235, %1233)\n  %1240 = Expand(%1220, %1239)\n  %1241 = Unsqueeze[axes = [-1]](%1240)\n  %1242 = Shape(%1233)\n  %1243 = ConstantOfShape[value = <Tensor>](%1242)\n  %1244 = Constant[value = <Scalar Tensor []>]()\n  %1245 = Mul(%1243, %1244)\n  %1246 = Equal(%1233, %1245)\n  %1247 = Where(%1246, %1243, %1233)\n  %1248 = Expand(%1222, %1247)\n  %1249 = Unsqueeze[axes = [-1]](%1248)\n  %1250 = Shape(%1233)\n  %1251 = ConstantOfShape[value = <Tensor>](%1250)\n  %1252 = Constant[value = <Scalar Tensor []>]()\n  %1253 = Mul(%1251, %1252)\n  %1254 = Equal(%1233, %1253)\n  %1255 = Where(%1254, %1251, %1233)\n  %1256 = Expand(%1224, %1255)\n  %1257 = Unsqueeze[axes = [-1]](%1256)\n  %1258 = Shape(%1233)\n  %1259 = ConstantOfShape[value = <Tensor>](%1258)\n  %1260 = Constant[value = <Scalar Tensor []>]()\n  %1261 = Mul(%1259, %1260)\n  %1262 = Equal(%1233, %1261)\n  %1263 = Where(%1262, %1259, %1233)\n  %1264 = Expand(%1226, %1263)\n  %1265 = Unsqueeze[axes = [-1]](%1264)\n  %1266 = Shape(%1233)\n  %1267 = ConstantOfShape[value = <Tensor>](%1266)\n  %1268 = Constant[value = <Scalar Tensor []>]()\n  %1269 = Mul(%1267, %1268)\n  %1270 = Equal(%1233, %1269)\n  %1271 = Where(%1270, %1267, %1233)\n  %1272 = Expand(%1228, %1271)\n  %1273 = Unsqueeze[axes = [-1]](%1272)\n  %1274 = Concat[axis = -1](%1241, %1249, %1257, %1265, %1273)\n  %1275 = Shape(%1159)\n  %1276 = Constant[value = <Tensor>]()\n  %1277 = Constant[value = <Tensor>]()\n  %1278 = Constant[value = <Tensor>]()\n  %1279 = Slice(%1275, %1277, %1278, %1276)\n  %1280 = Concat[axis = 0](%1233, %1279)\n  %1281 = Reshape(%1178, %1280)\n  %1282 = ScatterND(%1159, %1274, %1281)\n  %1283 = Constant[value = <Tensor>]()\n  %1284 = Constant[value = <Tensor>]()\n  %1285 = Constant[value = <Tensor>]()\n  %1286 = Constant[value = <Tensor>]()\n  %1287 = Slice(%1282, %1284, %1285, %1283, %1286)\n  %1288 = Exp(%1287)\n  %1289 = Constant[value = <Tensor>]()\n  %1290 = Mul(%1288, %1289)\n  %1291 = Constant[value = <Tensor>]()\n  %1292 = Reshape(%1290, %1291)\n  %1293 = Constant[value = <Tensor>]()\n  %1295 = ConstantOfShape[value = <Tensor>](%1555)\n  %1296 = Constant[value = <Scalar Tensor []>]()\n  %1297 = Mul(%1295, %1296)\n  %1298 = Constant[value = <Tensor>]()\n  %1299 = Equal(%1298, %1297)\n  %1300 = Where(%1299, %1295, %1293)\n  %1301 = Expand(%1292, %1300)\n  %1302 = Shape(%1282)\n  %1303 = Constant[value = <Scalar Tensor []>]()\n  %1304 = Gather[axis = 0](%1302, %1303)\n  %1305 = Cast[to = 7](%1304)\n  %1306 = Constant[value = <Scalar Tensor []>]()\n  %1307 = Constant[value = <Scalar Tensor []>]()\n  %1308 = Range(%1306, %1305, %1307)\n  %1309 = Shape(%1282)\n  %1310 = Constant[value = <Scalar Tensor []>]()\n  %1311 = Gather[axis = 0](%1309, %1310)\n  %1312 = Cast[to = 7](%1311)\n  %1313 = Constant[value = <Scalar Tensor []>]()\n  %1314 = Constant[value = <Scalar Tensor []>]()\n  %1315 = Range(%1313, %1312, %1314)\n  %1316 = Shape(%1282)\n  %1317 = Constant[value = <Scalar Tensor []>]()\n  %1318 = Gather[axis = 0](%1316, %1317)\n  %1319 = Cast[to = 7](%1318)\n  %1320 = Constant[value = <Scalar Tensor []>]()\n  %1321 = Constant[value = <Scalar Tensor []>]()\n  %1322 = Range(%1320, %1319, %1321)\n  %1323 = Shape(%1282)\n  %1324 = Constant[value = <Scalar Tensor []>]()\n  %1325 = Gather[axis = 0](%1323, %1324)\n  %1326 = Cast[to = 7](%1325)\n  %1327 = Constant[value = <Scalar Tensor []>]()\n  %1328 = Constant[value = <Scalar Tensor []>]()\n  %1329 = Range(%1327, %1326, %1328)\n  %1330 = Shape(%1282)\n  %1331 = Constant[value = <Scalar Tensor []>]()\n  %1332 = Gather[axis = 0](%1330, %1331)\n  %1333 = Cast[to = 7](%1332)\n  %1334 = Constant[value = <Scalar Tensor []>]()\n  %1335 = Constant[value = <Scalar Tensor []>]()\n  %1336 = Range(%1334, %1333, %1335)\n  %1337 = Constant[value = <Tensor>]()\n  %1338 = Constant[value = <Tensor>]()\n  %1339 = Constant[value = <Tensor>]()\n  %1340 = Constant[value = <Tensor>]()\n  %1341 = Slice(%1336, %1338, %1339, %1337, %1340)\n  %1342 = Constant[value = <Tensor>]()\n  %1343 = Reshape(%1308, %1342)\n  %1344 = Constant[value = <Tensor>]()\n  %1345 = Reshape(%1315, %1344)\n  %1346 = Constant[value = <Tensor>]()\n  %1347 = Reshape(%1322, %1346)\n  %1348 = Constant[value = <Tensor>]()\n  %1349 = Reshape(%1329, %1348)\n  %1350 = Constant[value = <Tensor>]()\n  %1351 = Reshape(%1341, %1350)\n  %1352 = Add(%1343, %1345)\n  %1353 = Add(%1352, %1347)\n  %1354 = Add(%1353, %1349)\n  %1355 = Add(%1354, %1351)\n  %1356 = Shape(%1355)\n  %1357 = Shape(%1356)\n  %1358 = ConstantOfShape[value = <Tensor>](%1357)\n  %1359 = Constant[value = <Scalar Tensor []>]()\n  %1360 = Mul(%1358, %1359)\n  %1361 = Equal(%1356, %1360)\n  %1362 = Where(%1361, %1358, %1356)\n  %1363 = Expand(%1343, %1362)\n  %1364 = Unsqueeze[axes = [-1]](%1363)\n  %1365 = Shape(%1356)\n  %1366 = ConstantOfShape[value = <Tensor>](%1365)\n  %1367 = Constant[value = <Scalar Tensor []>]()\n  %1368 = Mul(%1366, %1367)\n  %1369 = Equal(%1356, %1368)\n  %1370 = Where(%1369, %1366, %1356)\n  %1371 = Expand(%1345, %1370)\n  %1372 = Unsqueeze[axes = [-1]](%1371)\n  %1373 = Shape(%1356)\n  %1374 = ConstantOfShape[value = <Tensor>](%1373)\n  %1375 = Constant[value = <Scalar Tensor []>]()\n  %1376 = Mul(%1374, %1375)\n  %1377 = Equal(%1356, %1376)\n  %1378 = Where(%1377, %1374, %1356)\n  %1379 = Expand(%1347, %1378)\n  %1380 = Unsqueeze[axes = [-1]](%1379)\n  %1381 = Shape(%1356)\n  %1382 = ConstantOfShape[value = <Tensor>](%1381)\n  %1383 = Constant[value = <Scalar Tensor []>]()\n  %1384 = Mul(%1382, %1383)\n  %1385 = Equal(%1356, %1384)\n  %1386 = Where(%1385, %1382, %1356)\n  %1387 = Expand(%1349, %1386)\n  %1388 = Unsqueeze[axes = [-1]](%1387)\n  %1389 = Shape(%1356)\n  %1390 = ConstantOfShape[value = <Tensor>](%1389)\n  %1391 = Constant[value = <Scalar Tensor []>]()\n  %1392 = Mul(%1390, %1391)\n  %1393 = Equal(%1356, %1392)\n  %1394 = Where(%1393, %1390, %1356)\n  %1395 = Expand(%1351, %1394)\n  %1396 = Unsqueeze[axes = [-1]](%1395)\n  %1397 = Concat[axis = -1](%1364, %1372, %1380, %1388, %1396)\n  %1398 = Shape(%1282)\n  %1399 = Constant[value = <Tensor>]()\n  %1400 = Constant[value = <Tensor>]()\n  %1401 = Constant[value = <Tensor>]()\n  %1402 = Slice(%1398, %1400, %1401, %1399)\n  %1403 = Concat[axis = 0](%1356, %1402)\n  %1404 = Reshape(%1301, %1403)\n  %1405 = ScatterND(%1282, %1397, %1404)\n  %1406 = Constant[value = <Tensor>]()\n  %1407 = Constant[value = <Tensor>]()\n  %1408 = Constant[value = <Tensor>]()\n  %1409 = Constant[value = <Tensor>]()\n  %1410 = Slice(%1405, %1407, %1408, %1406, %1409)\n  %1411 = Constant[value = <Scalar Tensor []>]()\n  %1412 = Mul(%1410, %1411)\n  %1413 = Constant[value = <Tensor>]()\n  %1414 = Reshape(%1412, %1413)\n  %1415 = Constant[value = <Tensor>]()\n  %1417 = ConstantOfShape[value = <Tensor>](%1556)\n  %1418 = Constant[value = <Scalar Tensor []>]()\n  %1419 = Mul(%1417, %1418)\n  %1420 = Constant[value = <Tensor>]()\n  %1421 = Equal(%1420, %1419)\n  %1422 = Where(%1421, %1417, %1415)\n  %1423 = Expand(%1414, %1422)\n  %1424 = Shape(%1405)\n  %1425 = Constant[value = <Scalar Tensor []>]()\n  %1426 = Gather[axis = 0](%1424, %1425)\n  %1427 = Cast[to = 7](%1426)\n  %1428 = Constant[value = <Scalar Tensor []>]()\n  %1429 = Constant[value = <Scalar Tensor []>]()\n  %1430 = Range(%1428, %1427, %1429)\n  %1431 = Shape(%1405)\n  %1432 = Constant[value = <Scalar Tensor []>]()\n  %1433 = Gather[axis = 0](%1431, %1432)\n  %1434 = Cast[to = 7](%1433)\n  %1435 = Constant[value = <Scalar Tensor []>]()\n  %1436 = Constant[value = <Scalar Tensor []>]()\n  %1437 = Range(%1435, %1434, %1436)\n  %1438 = Shape(%1405)\n  %1439 = Constant[value = <Scalar Tensor []>]()\n  %1440 = Gather[axis = 0](%1438, %1439)\n  %1441 = Cast[to = 7](%1440)\n  %1442 = Constant[value = <Scalar Tensor []>]()\n  %1443 = Constant[value = <Scalar Tensor []>]()\n  %1444 = Range(%1442, %1441, %1443)\n  %1445 = Shape(%1405)\n  %1446 = Constant[value = <Scalar Tensor []>]()\n  %1447 = Gather[axis = 0](%1445, %1446)\n  %1448 = Cast[to = 7](%1447)\n  %1449 = Constant[value = <Scalar Tensor []>]()\n  %1450 = Constant[value = <Scalar Tensor []>]()\n  %1451 = Range(%1449, %1448, %1450)\n  %1452 = Shape(%1405)\n  %1453 = Constant[value = <Scalar Tensor []>]()\n  %1454 = Gather[axis = 0](%1452, %1453)\n  %1455 = Cast[to = 7](%1454)\n  %1456 = Constant[value = <Scalar Tensor []>]()\n  %1457 = Constant[value = <Scalar Tensor []>]()\n  %1458 = Range(%1456, %1455, %1457)\n  %1459 = Constant[value = <Tensor>]()\n  %1460 = Constant[value = <Tensor>]()\n  %1461 = Constant[value = <Tensor>]()\n  %1462 = Constant[value = <Tensor>]()\n  %1463 = Slice(%1458, %1460, %1461, %1459, %1462)\n  %1464 = Constant[value = <Tensor>]()\n  %1465 = Reshape(%1430, %1464)\n  %1466 = Constant[value = <Tensor>]()\n  %1467 = Reshape(%1437, %1466)\n  %1468 = Constant[value = <Tensor>]()\n  %1469 = Reshape(%1444, %1468)\n  %1470 = Constant[value = <Tensor>]()\n  %1471 = Reshape(%1451, %1470)\n  %1472 = Constant[value = <Tensor>]()\n  %1473 = Reshape(%1463, %1472)\n  %1474 = Add(%1465, %1467)\n  %1475 = Add(%1474, %1469)\n  %1476 = Add(%1475, %1471)\n  %1477 = Add(%1476, %1473)\n  %1478 = Shape(%1477)\n  %1479 = Shape(%1478)\n  %1480 = ConstantOfShape[value = <Tensor>](%1479)\n  %1481 = Constant[value = <Scalar Tensor []>]()\n  %1482 = Mul(%1480, %1481)\n  %1483 = Equal(%1478, %1482)\n  %1484 = Where(%1483, %1480, %1478)\n  %1485 = Expand(%1465, %1484)\n  %1486 = Unsqueeze[axes = [-1]](%1485)\n  %1487 = Shape(%1478)\n  %1488 = ConstantOfShape[value = <Tensor>](%1487)\n  %1489 = Constant[value = <Scalar Tensor []>]()\n  %1490 = Mul(%1488, %1489)\n  %1491 = Equal(%1478, %1490)\n  %1492 = Where(%1491, %1488, %1478)\n  %1493 = Expand(%1467, %1492)\n  %1494 = Unsqueeze[axes = [-1]](%1493)\n  %1495 = Shape(%1478)\n  %1496 = ConstantOfShape[value = <Tensor>](%1495)\n  %1497 = Constant[value = <Scalar Tensor []>]()\n  %1498 = Mul(%1496, %1497)\n  %1499 = Equal(%1478, %1498)\n  %1500 = Where(%1499, %1496, %1478)\n  %1501 = Expand(%1469, %1500)\n  %1502 = Unsqueeze[axes = [-1]](%1501)\n  %1503 = Shape(%1478)\n  %1504 = ConstantOfShape[value = <Tensor>](%1503)\n  %1505 = Constant[value = <Scalar Tensor []>]()\n  %1506 = Mul(%1504, %1505)\n  %1507 = Equal(%1478, %1506)\n  %1508 = Where(%1507, %1504, %1478)\n  %1509 = Expand(%1471, %1508)\n  %1510 = Unsqueeze[axes = [-1]](%1509)\n  %1511 = Shape(%1478)\n  %1512 = ConstantOfShape[value = <Tensor>](%1511)\n  %1513 = Constant[value = <Scalar Tensor []>]()\n  %1514 = Mul(%1512, %1513)\n  %1515 = Equal(%1478, %1514)\n  %1516 = Where(%1515, %1512, %1478)\n  %1517 = Expand(%1473, %1516)\n  %1518 = Unsqueeze[axes = [-1]](%1517)\n  %1519 = Concat[axis = -1](%1486, %1494, %1502, %1510, %1518)\n  %1520 = Shape(%1405)\n  %1521 = Constant[value = <Tensor>]()\n  %1522 = Constant[value = <Tensor>]()\n  %1523 = Constant[value = <Tensor>]()\n  %1524 = Slice(%1520, %1522, %1523, %1521)\n  %1525 = Concat[axis = 0](%1478, %1524)\n  %1526 = Reshape(%1423, %1525)\n  %1527 = ScatterND(%1405, %1519, %1526)\n  %1530 = Unsqueeze[axes = [0]](%1147)\n  %1533 = Concat[axis = 0](%1530, %1557, %1558)\n  %1534 = Reshape(%1527, %1533)\n  %classes = Concat[axis = 1](%1119, %1534)\n  return %classes, %boxes, %1159\n}\n"
     ]
    }
   ],
   "source": [
    "onnx.checker.check_model(onnx_model)  # Check that the IR is well formed\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))  # Print a human readable representation of the graph\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"yolo-fastest.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "x_array = to_numpy(x)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: x_array}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 2400, 7])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "torch_out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 7199 / 16800 (42.9%)\nMax absolute difference:      18.784\nMax relative difference:      926.65\n x: array([[[     23.568,      23.629,      56.809, ...,  3.3659e-05,    0.024694,     0.98144],\n        [     48.964,      25.784,       100.7, ...,   0.0002009,    0.012027,     0.98966],\n        [     83.122,       25.89,      160.56, ...,  0.00016407,   0.0055412,     0.99455],...\n y: array([[[     23.568,      23.629,      56.809, ...,     -10.299,     -3.6762,      3.9682],\n        [     48.964,      25.784,       100.7, ...,     -8.5125,     -4.4085,      4.5613],\n        [     83.122,       25.89,      160.56, ...,      -8.715,       -5.19,       5.206],...",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-29f2a1871e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compare ONNX Runtime and PyTorch results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch_out_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_out_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exported model has been tested with ONNXRuntime, and the result looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[0;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[0;32m-> 1528\u001b[0;31m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    838\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 7199 / 16800 (42.9%)\nMax absolute difference:      18.784\nMax relative difference:      926.65\n x: array([[[     23.568,      23.629,      56.809, ...,  3.3659e-05,    0.024694,     0.98144],\n        [     48.964,      25.784,       100.7, ...,   0.0002009,    0.012027,     0.98966],\n        [     83.122,       25.89,      160.56, ...,  0.00016407,   0.0055412,     0.99455],...\n y: array([[[     23.568,      23.629,      56.809, ...,     -10.299,     -3.6762,      3.9682],\n        [     48.964,      25.784,       100.7, ...,     -8.5125,     -4.4085,      4.5613],\n        [     83.122,       25.89,      160.56, ...,      -8.715,       -5.19,       5.206],..."
     ]
    }
   ],
   "source": [
    "# compare ONNX Runtime and PyTorch results\n",
    "torch_out_array = [to_numpy(torch_out[0]), to_numpy(torch_out[1][0]),to_numpy(torch_out[1][1])]\n",
    "np.testing.assert_allclose(torch_out_array[0], ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(torch_out_array[1], ort_outs[1], rtol=1e-03, atol=1e-05)\n",
    "np.testing.assert_allclose(torch_out_array[2], ort_outs[2], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.3 64-bit ('base': conda)",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bbd1dd37a092b7f1b47b572bc72841591b000e42b11a51f7bec7c58a01a3fca1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}